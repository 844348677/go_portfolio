ch03 Pods:running containers in Kubernetes
	creating, running, and stopping pods
	organizing pods and other resources with labels
	performing an operation on all pods with a specific label
	using namespaces to split pods into non-overlapping groups
	scheduling pods onto specific types of worker nodes

Introducing pods
when a pod does contain multiple containers, all of them are always run on a single worker node, it never spans multiple worker nodes

Understanding why we need pods

Understanding why multiple containers are better than one container running multiple precess
containers are designed to run only a single process per container (unless the process itself spawn)

Understanding pods
you need another higher-level construct that will allow you to bind containers together and manage them as a single unit
almost the same environment as if ther were all running in a single container, while keeping them somewhat isolated
you can take advangtage of all the features containers provide, while at the same time giving the processes the illusion of running together

Understanding the partial isolation between containers of the same pod
you want to isolate groups of containers instead of individual ones
Kubernetes achieves this by configuring Docker to have all container of a pod share the same set of Linux namespaces instead of each container having its own set
Because all containers of a pod run under the same Network and UTS namespaces(Linux namespace here), they all share the same hostname and network interfaces
similarly, all container of a pod run under the same IPC namespace and can communicate through IPC (Inter-Process Communication), and can communication through IPC. (PID namespace)
when containers of the same pod use seperate PID namespaces, you only see the contaienr's own processes when running ps aux in the container
But when ti comes to the filesystem, things are a little different.
because most of the container's filesystem comes from the container image, by default, the filesystem of each container is fully isolated from other containers
using a Kubernetes concept called a Volume

Understanding how containers share the same IP and PORT space
because containers in a pod run in the same Network namespace, they share the same IP address and port space
ports conflicts

Introducing the flat inter-pod network
every pod can access every other pod at the other pod's IP address
communication between pods is always simple
it doesn't matter if two pod are sheduled onto a single or onto different worker nodes
containers inside those pods can communicate with each other across the flat NAT-less (Network Address Translation) network, much like computers on a local area network (LAN)
pods are logical hosts and behave much like physical hosts or VMs in the non-container world

Organizing containers across pods properly
you should think of pods as seperate mahines
unlike the old days, when we used to cram all sorts of apps onto the same hosts
you should organize app into multiple pods, where each one contains only tightly related components or process

Splitting multi-tier apps into multiple pods

Splitting into multiple pods to enable individual scaling
Kubernetes can't horizontally scale individual containers; instead, it scales whole pods

Understanding when to use multiple containers in a pod
wehn the application consists of one process and one or more complementary process
Pods should contain tightly coupled containers, usually a main container and contianers that support the main one
for example, the main container in a pod could be a web server that serves files from a certain file directory, while an additional container (a sidecar container) periodically downloads content from an external source and stores it in the web server's directory
(use a Kubernetes Volume that you mount into both containers)

Deciding when to use multiple containers in a pod
recap how container should be grouped into pods
	Do they need to be run together or can they run on different hosts
	Do they represent a single whole or are they independent components
	Must they be scaled together or individually
a container shouldn't run multiple process. a pod shouldn't contain multiple containers if they don't need to run on the same machine

Creating pods from YAML or JSON descriptors
pods an other kubernetes resources are usually created by posting a JSON or YAML manifest to the Kubernetes REST API endpoint

Examining a YAML descriptor of an existing pod
you'll use the kubectl get command with the -o yaml option to get the whole YAML definition of the pod

$ kubectl get po kubia-zxzij -o yaml

Introducing the main parts of a pod definition
first, there's the Kubernetes API version used in the YAML and the type of resource the YAML is describing
then, three important section are found in almost all Kubernets resouces
	Metadata includes the name, namespace, labels, and other infromation about the pod
	Spec contains the actual description of the pod's contents, such as the pod's containers, volumes, and other data
	Status contains the current information about the running pod, such as what condition the pod is in, the description and status of each container, and the pod's inteernal IP and other basic info
the status part contains read-only runtime data that shows the state of the resource at a given moment.

Creating a simple YAML descriptor for a pod
// Descriptor conforms to version v1 of Kubernetes API
apiVersion: V1
// you're describing a pod
kind: Pod
metadata:
	// the name of the pod
  name: kubia-manual
spec:
  containers:
  	// Container image to create the container from 
    - image: 844348677/kubia
    	// name of the contaienr
       name: kubia
       // the port the app is listening on
       ports:
       - containerPort: 8080
          protocol: TCP

Specifying container ports
it makes sense to define the ports explicitly so that everyone using your cluster can quickly see what ports each pod exposes
explicitly defining ports also allows you to assign a name to each port

$ kubectl explain pods
$ kubectl explain pod.spec

Using kubectl create to create the pod
to create the pod from your YAML file, use the kubectl create command

$ kubectl create -f kubia-manual.yaml

the kubectl create -f command is used fro creating any resource (not only pods) from a YAML or JSON file

Retrieving the whole definition of a running pod
after creating the pod, you can ask Kubernetes for the full YAML of the pod

$ kubectl get po kubia-manual -o yaml
$ kubectl get po kubia-manual -o json

Seeing your newly created pod in the list of pods

$ kubectl get pods

Viewing application logs
containerized application usually log to the standard output and standard error stream instead of writing their logs to files
the container runtime (Docker in your case) redirects those stream to files and allow you to get the container's log by running

$ docker logs <container id>

Retrieving a pod's log with kubectl logs

$ kubectl logs kubia-manual

Specifying the container name when getting logs fo a multi-container pod

$ kubectl logs kubia-manul -c kubia

centralized, cluster-wide logging, which stores all the logs into a central store

Sending requests to the pod
the kubectl expose command to create a service to gain access to the pod externally
other ways of connecting to a pod for testing and debugging purposes
one of them is through port forwarding

Forwarding a local network port to a port in the pod
when you want to talk to a specific pod without going through a service (for debugging or other reasonss), Kubernetes allows you to configure port forwarding to the pod
local port 8888 to port 8080 of your kubia-manual pod

$ kubectl port-forward kubia-manual 8888:8080

Connecting to the pod trough the port forwarder

$ curl localhost:8888

using port forwarding like this is an effective way to test an individual pod








