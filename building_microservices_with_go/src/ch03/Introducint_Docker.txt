Introducint Docker

Introducing Containers with Docker
the desire to simplify the process of building,shipping ,and running application

A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it:
code, runtime, system tools, system libraries , setting
Containers isolate software from its surroundings, for example, differences between development and staging
environments and help reduce conflicts between teams running different software on the same infrastructure

Containers have become the primary choice fro package microservices
Containers work by isolating processes and filesystems from each other

Installing Docker

Running our first container

think of it like types and instances ,
 a type defines fields and methods making up behavior
 an instance is a living instantiation of this type

 docker run --rm hello-world

 when you execute a docker run the first thing the engine does is check to see if you have the image isntalled locally
 if it doesn't then it connects to the default registry, to retrieve it

 the --rm flag tells the Docker engine to remove the container and delete any resources such as volumes it was using on exit

we will start a container and create a shell inside of it to show how you can navigate to the internal file system

docker run -it --rm alpine:latest sh
sudo docker run -it --rm alpine:latest sh

alpine is a lightweight version of linux and is perfect for running Go application.
the -it flags stand for interactive terminal it maps the standard in from your terminal to the input of the running container
the sh statement after the name of the image we want to run is the name of the command we would like to execute in the container when it start

if all want well , you should now be inside a shell of the container

ls

bin    etc    lib    mnt    root   sbin   sys    usr
dev    home   media  proc   run    srv    tmp    var
This is the root folder of the newly started container ,
container are immutable,
so any changes you make to the file system in a running container is disposed of when the container is stopped

Container are immutable instances of images, and the data volumes are by default non-persistent

docker ps

The docker ps command queries the engine and returns a list of the container,
by default this only shows the running container, if we add the -a flag we can alse see stopped containers

docker ps -a

jump back to the Apline Linux container , create a file in the root file system

touch mytestfile.txt

exit

docker ps

docker ps -a

"Container are immutable instance of images, and the data volumes are by default non-persistent"

there is something worth noting, however, unless you explicity remove a container it will persist in a stopped state on the Docker host

Removing containers is important to remember for two reasons
this first is that if you do not remember this,
you will fill up the disk on your host quickly as every time you create a container Docker will allocates space on the host fro the container volumes
the second is that the container can be restarted

restarted that sounds cool, in fact, it is a handy feature, not something you should use in your production environment,
for that you need to remember the golden rule and design your application accordingly

restart a stopped container

docker start -it [container_id] sh
这个命令现在不对了！！！
重启docker  再进入docker container
sudo docker restart   1861653d703c
sudo docker attach 1861653d703c

When running in a production environment , you cannot ensure that you can restart a container

docker rm container_id

if you want to remove all the stopped containers you can use the following command

docker rm -v $(docker ps -a -q)

the docker ps -a -q the -a flag will list all the containers including the stopped ones,
-q will return a list of the container IDs rather than the full details.
we are passing this as a parameter list to docker rm, whick will remove all the containers in the lsit

to avoid having to remove a container we can use the --rm flag when starting a new container.
this flag tell Docker to remove the container when it stops

Docker volumes
there are some instances when you may wish to write some files to a disk or when you want to read data from a disk such as in a development setup
Docker has the concept of voluemes , which can be mounted either from the host running the Docker machine or from another Docker container.

Union filesystem
the concept of a Union File System
The Union filesystem allows us to represent a logical file system by grouping different directories and or files together
it uses a Copy on Write technique,
which copies the layer when we modify the file system,
this way we only use about 1MB of space when creating a new image
when data is written to the file system   Docker copies th layer an puts it on the top of the stack

Mounting volumes
The -v , or --volume parameter allows you to specify a pair of values corresponding to the file system
you wish to mount on the host and the path where you would like to mount the volume inside the container

this time mounting a volume on the local file system

sudo docker run -it -v $(pwd):/host alpine:latest /bin/sh

if you change into thte host folder, you will see that there is access to the same folder from there you ran the docker run command

-v hostfolder:destinationfolder

this paths need to be absolute , and you cannot use a relative path like ./ or ../foldername
the volume you have just mounted has read/write access
any changes you make will be synchronized to the folder on the host so be careful to not go running

Docker ports
when running web application inside a container it is quite common that we will need to expose some ports to he outside world
By defualt, a Docker container is completely isolated,
and if you start a server running on port 8080 inside your container unless you explicitly specify that port is accessible from the outsied,
it will not be accessible

Mappint ports

cd /home/liuh/go/go_portfolio/building_microservices_with_go/src/ch01/basic_http_example
sudo docker run -it --rm -v $(pwd):/src -p 8080:8080 -w /src golang:alpine /bin/sh

Move to the folder where you checked out the sample code, and run the following Docker command: 上面

Unable to find image 'golang:alpine' locally
alpine: Pulling from library/golang

go run example.go

2018/07/27 14:14:17 server staring on port 8080

The -w flag : is to set the working directory
that means that any command we run in the container will be run inside this folder
When we start the shell , you will see that rather than having to change into the folder we specify in the second part of the volume mounting we are alreading in that folder
and can run our application
using a slightly different image this time
golang:alpine :
which is a version of Alpine with the most recent Go tools installed

curl -XPOST localhost:8080/helloworld

ch01 中的　json4　有完整的代码
cd /home/liuh/go/go_portfolio/building_microservices_with_go/src/ch01/r_w_json_4
curl -XPOST localhost:8080/helloworld -d '{"name":"Nic"}'

{"message":"Hello Nic"}

docker ps

-p
this takes a pair of values separated by a colon(:)
the first is the destination port on the host that we would like to bing to
the second is the source port on the Docker container to which our application is bound

you would not be able to start the program locally twice because of the port binding

we can do this one command by replacing the /bin/sh command with our go run command

sudo docker run -it --rm -v $(pwd):/src -p 8080:8080 -w /src golang:alpine go run json_4.go
curl -XPOST localhost:8080/helloworld -d '{"name":"Nic"}'

like volumes, you can specify multiple instances of the -p argument, which enables you to set up the bingding for multiple ports

Removing a container starting with an explicit name

Removing a container starting with an explicit name
Containers that start with a name parameter are not automatically removed even if you specify the -rm argument
if we append the -v option to the command , we can also remove the volumes that are associated with it

docker rm -v server

Docker networking
Docker networking is an interesting topic, and by default, Docker supports the following network modes:
bridge
host
none
orverly

Bridge networking
The bridge network is the default network that your container will connect ot when you launch them
this is how we were able to join our containers together in the last example
to facilitate this, Docker uses some of the core Linux capabilities such as networkding namespaces and virtual Ethernet interfaces(or veth interfaces)

When the Docker engine starts , it creates the docker0 virtual interface on the host machine
The docker0 interface is a virtual Ethernet bridge that automatically forwards packets between any other network interfaces that are attached to it.
when a container starts it creates a veth pair, it gives one to the container, which becomes its eth0, and the other connects to the docker0 bridge

http://172.17.0.1:8080/helloworld
http://192.168.1.104:8080/helloworld
http://127.0.0.1:8080/helloworld
都能访问

Host networking
the host network is essentially the same network that the Docker engine is running on.
when you connect a container to the host network all of the ports that are exposed by the container are automatically mapped to the hosts,
it alse shares the IP address of the host
while this may seem like a nice convenience , Docker was always designed to be capable of running multiple instances of the same container on the engine,
and since you can only bind a socket to one port in Linux using the host network limits this feature

the host network can also pose a security risk to your container as it is no longer protected by the principle of no trust
and you no longer have the ability to explicitly control if a port is exposed or not
that being said
due to the efficiencies of host networking it may in some instances be appropriate to connect a container to the host network if you anticipate that it is going to heavily use the network
就是预期有大量的使用网络，将container链接到host network ，因为　host networking 高效
An APi gateway might be on such example,
this container would still be possible to route request to other API containers that are sitting on the bridge network

No network
Removing your container from any network might in som instance be something you wish to do

Overlay network
The Docker overlay network is a unique Docker network that is used to connect containers running on seperate hosts to on another.
developing software one host all containers
production be running multiple hosts, each running multiple containers
the containers still need to talk to one another , and while we could route all traffic through
an ESB (enterprise service bus)
this is a little bit of an anti-pattern in the microservice world
it is in effect a network tunnel between machines which passes the traffic unmodified over th physical network
the problem with the overly is that you can no longer rely on Docker to update the etc/hosts file for you,
and you must depend on a dynamic service registry

Custom network drivers
Docker also supports plugins for networking ,
based around its open source libnetwork project
you can write custom networking plugin that can replace the networking subsystem of the Docker engine

Weaveworks

Project Calico

Creating custom bridge networks

To see the currently running networks on your docker engine, we can execute the following command

docker network ls

NETWORK ID          NAME                DRIVER              SCOPE
7f821b53187e        bridge              bridge              local
e15e0af7abc4        host                host                local
8a3854681d21        none                null                local

Creating a bridge network
To create a bridge network, we can use th following command:

docker network create testnetwork

when you create a network it use the bridge as a default driver
it uses the bridge as a default driver

Connecting containers to custom network

docker run -it --rm -v $(pwd):/src -w /src --name server --network=testnetwork golang:alpine go run json_4.go

let's try to curl the container using the same command we excuted earlier

docker run --rm appropriate/curl:latest curl -i -XPOST server:8080/helloworld -d '{"name":"Nic"}'

curl: (6) Could not resolve host: server

sudo docker run --rm --network=testnetwork appropriate/curl:latest curl -i -XPOST server:8080/helloworld -d '{"name":"Nic"}'

//需要制定　--network  指定名字　

Writing Dockerfiles
Dockerfiles are the recipes for our images
the define the base image , software to be installed and give us the capability to set the various structure that our application needs

Building application code for Docker
!!!!

CGO_ENABLED=0 GOOS=linux GOARCH=386 go build -a -installsuffix cgo -ldflags '-s' -o server

we are passing the argument -ldflags '-s' this argument passes the -s argument to the linker when we build the application
and tell it to statically link all dependencies
// 把所有的静态　link 引用进来　因为要使用 Scratch　container ,里面没有　C library GLibC
this is very useful when we use the popular Scratch container as a base
Scratch is the lightest base you can get it has no application frameworks or application
this is opposed to Ubuntu , which takes about 150MB
The difference between Scratch and Ubuntu is that Scratch does not have access to the standard C library GLibC

if we do not build a static binary, then it will not execute if we try to run it in a Scratch container
the reason :
Go application is a static binary but it still has a dependency on GLibC, both the net and the os/user package
link ot GLibC so if we are to run our application with a Scratch base image we need to statically link this
the benefit , however, is an incredibly small image, we end up with an image which is roughly 4MB in size

not using Linux
prefix the architecture varaibles GOOS=linux GOARCH=386 to your go build command as we did in the earlier example
测试
go build -a -installsuffix cgo -ldflags '-s' -o server

Dokcer file

FROM
the FROM instruction set the base image for subsequent instructions
you can use any image that is either stored in a remote registry or locally on your Docker Engine

FROM image // assuming latest
FROM image:tag // where you can specify a tag to use

scratch , this is a particular kind of image, which is basically a blank canvas　画布
we could use Ubuntu or Debian or Alpine or pretty much anything really
use scratch to produce the smallest possible image

MAINTAINER
The MAINTAINER instruction allows you to set the author of the generated image

EXPOSE
The EXPOSE instruction informs Docker that the container listens on the specified networks ports at runtime
Expose does not make the ports accessible to the host
this function still needs to be performed with the -p mapping

COPY
The COPY instruction copies files
from the source in the first part of this instruction
to the destination specified in the second part

COPY <src> <dest>
COPY ["<src>", "<dest>"] // useful when paths contain whitespace

<src> must be part of the context for the build, you cannot specify relative folders such as ../
A root / specified in the <src> will be the root of the context
A root / specified in the <dest> will map to the containers root file system
Specifying a COPY instruction without a destination will copy the file or folder into the WORKDIR with the same name as the original

ENTRYPOINT
An ENTRYPOINT allows you to configure the executable that you would like to run when your container starts
Using ENTRYPOIT makes it possible to specify arguments as part of the docker run command which is appended to the ENTRYPOINT
ENTRYPOINT has two forms:
ENTRYPOINT ["excutable","param1","param2"] // preferred form
ENTRYPOINT command param1 param2 //shell form

ENTRYPOINT ./server . this is our Go binary that we would like to run

We can pass additional arguments to the application via the docker run command arguments

docker run --rm helloworld --config=/configfile.json

CMD
The CMD instruction has three forms
CMD ["executable","param1","param2"] // exec form
CMD ["param1","param2"] // append default parameter to ENTRYPOINT
CMD command param1 param2 //shell form

if we specify a default value for CMD, we can still override it by passing the command arguments to the docker urn command
Only one CMD instruction is permitted in a Docker file

Good practice for creating Dockerfiles
Every time we issue a command in the Dockerfile , Docker will create a new layer
When we mutate this command, the layer must be completely recreated and potentially all the following layers too
which can dramatically slow down your build
group your commands as tightly as possible to reduce the possibility of this occurring

RUN apt-get update
RUN apt-get install -y wget
RUN apt-get install -y curl
RUN apt-get isntall -y nginx

RUN apt-get update && apt-get install -y wget curl nginx

The second example would only create one layer

Building images from Dockerfiles

docker build -t testserver .

the -t argument is the tag we wish to give the container, this takes the form name:tag,
if we omit the tag portion of the argument as we have in our example command,
then the tag latest will be automatically assigned

docker images

你丫的　书又错了　dockerfile 中　改　再运行　sudo docker build -t testserver .
好像不是书的错，　是 go build 我没加　禁止交叉编译的问题
CGO_ENABLED=0 go build -a -installsuffix cgo -ldflags '-s' -o server
测试　不设置禁止交叉变异
go build -a -installsuffix cgo -ldflags '-s' -o server
COPY ./server ./server

docker: Error response from daemon: OCI runtime create failed: container_linux.go:348: starting container process caused "exec: \"/bin/sh\": stat /bin/sh: no such file or directory": unknown.

还是　书的问题　dockerfile 最后一行需要修改
ENTRYPOINT ["./server"]

sudo docker run --rm -p 8080:8080 testserve
curl -XPOST localhost:8080/helloworld -d '{"name":"Nic"}'


OK

CGO_ENABLED=0 go build -a -installsuffix cgo -ldflags '-s' -o server

Dockerfile :
FROM scratch

MAINTAINER liuh

EXPOSE 8080

COPY ./server ./

ENTRYPOINT ["./server"]

sudo docker build -t testserver .
sudo docker run --rm -p 8080:8080 testserver
curl -XPOST localhost:8080/helloworld -d '{"name":"liuh"}'

The final argument is the context we would like to send to the Docker Engine
run a Docker build, the context is automatically forward to the server
the Docker Engine will not be running on your local machine, and therefore it will not have access to your local filesystem

Docker build context
Docker build command,
we set the context path as the final argument.
the context is transferred to the server
only send the files you need to be packaged inside the container or the files you need when building the container
two ways
the first is to ensure that our context only has the files on it we require
secondary option of using a .dockerignore file

Dcker Ignore files
https://godoc.org/path/filepath#Match

Running Daemons in containers
one of the things
to use a Daemon runner such as initd or systemd to ensure that
the application is started in the background and continues to run even if it crashes
This is an anti-pattern when you are using Docker containers,
for Docker to successfully stop the application it will attempt to kill the process running with PID 1
Daemon will generally start with PID 1 and start your application with another process ID,
which will mean they are not killed when you stop the Docker container

Docker Compose
That was all super easy-ish ????
a compelling feature of Docker that allows you to start multiple containers at once with your stack defination stored in a handy YAML file

Installing Docker Compose on Linux
Linux, need to install this yourself
// https://docs.docker.com/compose/

sudo pip install -U docker-compose
docker-compose version
sudo docker version

version: '2'
services:
    testserver:
        image:testserver
    curl:
        image:appropriate/curl
        entrypoint sh -c "sleep 8 && curl -XPOST testserver:8080/helloworld -d'{\"name\":\"Nic\"}'"

Docker Compose files  are written in YAML,
inside this file you can define services that will make up your application
two services
the first is image:testserver
the second is a simple service that curls this API

Line 1 defines the version of the Docker compose file we are using
version 2 is the latest version and is a breaking change from
version 1 which along with the --link directive is now deprecated and will be removed in
我看官网的　版本都３了！

in line 2 we define the services .
Services are the containers that you would like to start with your stack
Each service has to have unique name to the compose file,
but not necessarily to all the containers running on your Docker Engine
To avoid conficts when starting a stack
-p projectname to the docker-compose up
this will prefix the name of any of our container with the specified project name

The minimum information you need to specify for a service is the image

Line 6 defines our second service ,
execute a command

Service startup









